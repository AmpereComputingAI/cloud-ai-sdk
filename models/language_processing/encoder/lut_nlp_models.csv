MODEL_NAME,TASK,BATCH_SIZE,SEQUENCE_LENGTH,CORES,INSTANCES,OLS,MOS,EXTRA,SET_SIZE,PRECISION,OBJECTIVE,THPS,LATENCY
albert-base-v2,question-answering,8,128,2,7,4,1, ,2,fp16,best-throughput,2187.3,52.26
albert-base-v2,default,6,128,2,7,4,1, ,4,fp16,best-throughput,2177.7,78.48
allenai/scibert_scivocab_uncased,question-answering,6,128,2,7,,1, -multicast-weights,2,fp16,best-throughput,2402.6,35.22
allenai/scibert_scivocab_uncased,default,10,128,2,7,2,1, -multicast-weights,2,fp16,best-throughput,2390,59.07
avichr/heBERT_sentiment_analysis,text-classification,5,128,1,14,1,, -multicast-weights,4,fp16,best-throughput,2252.7,125.96
beomi/kcbert-base,question-answering,5,128,1,14,2,1, ,3,fp16,best-throughput,2227.3,95.14
beomi/kcbert-base,fill-mask,3,128,4,3,2,1, ,2,fp16,best-throughput,724.1,26.04
bert-base-cased,question-answering,8,128,2,7,4,1, -multicast-weights,1,fp16,best-throughput,2370,24.03
bert-base-cased,fill-mask,6,128,7,2,2,1, ,2,fp16,best-throughput,748.6,33.79
bert-base-chinese,question-answering,8,128,2,7,1,1, ,4,fp16,best-throughput,2480.9,90.69
bert-base-chinese,fill-mask,10,128,4,3,1,1, ,3,fp16,best-throughput,994.5,93.25
bert-base-german-cased,question-answering,8,128,2,7,1,1, -multicast-weights,2,fp16,best-throughput,2151.2,53.04
bert-base-german-cased,fill-mask,9,128,6,2,1,1, -multicast-weights,2,fp16,best-throughput,710.7,53.89
bert-base-multilingual-cased,question-answering,8,128,2,7,4,1, ,4,fp16,best-throughput,2476.8,91.64
bert-base-multilingual-cased,fill-mask,6,128,7,2,2,7, ,2,fp16,best-throughput,169.9,174.32
bert-base-multilingual-uncased,question-answering,5,128,1,14,1,1, ,3,fp16,best-throughput,2467.2,86.93
bert-base-multilingual-uncased,fill-mask,8,128,7,2,1,7, -multicast-weights,2,fp16,best-throughput,198.4,182.97
bert-base-uncased,question-answering,10,128,2,7,1,1, -multicast-weights,1,fp16,best-throughput,2367.5,29.96
bert-base-uncased,fill-mask,8,128,6,2,1,6, -multicast-weights,2,fp16,best-throughput,706.7,46.69
bert-large-uncased,question-answering,6,128,2,7,2,1, -multicast-weights,3,fp16,best-throughput,701.3,186.27
bert-large-uncased,fill-mask,4,128,2,7,1,1, ,2,fp16,best-throughput,530,119.51
bert-large-uncased-whole-word-masking-finetuned-squad,question-answering,6,128,2,7,,1, -multicast-weights,4,fp16,best-throughput,696.7,243.59
bert-large-uncased-whole-word-masking-finetuned-squad,default,4,128,2,7,2,1, -multicast-weights,2,fp16,best-throughput,663.9,86.43
bhadresh-savani/distilbert-base-uncased-emotion,text-classification,5,128,1,14,2,1, ,1,fp16,best-throughput,4715.4,15.31
camembert-base,question-answering,5,128,1,14,4,1, -multicast-weights,2,fp16,best-throughput,2230.4,63.51
camembert-base,fill-mask,9,128,6,2,1,1, ,2,fp16,best-throughput,671,56.43
cardiffnlp/twitter-roberta-base-sentiment,text-classification,10,128,2,7,2,1, ,2,fp16,best-throughput,2463.1,57.48
cardiffnlp/twitter-roberta-base-sentiment-latest,text-classification,8,128,2,7,1,1, ,3,fp16,best-throughput,2411.2,70.52
ckiplab/albert-tiny-chinese,question-answering,8,128,1,14,4,1, -multicast-weights,4,fp16,best-throughput,17620.5,25.99
ckiplab/albert-tiny-chinese,fill-mask,1,128,12,1,2,1, ,4,fp16,best-throughput,1164.8,3.6
classla/bcms-bertic-ner,token-classification,4,128,1,14,,, ,3,fp16,best-throughput,2283.6,75.04
cl-tohoku/bert-base-japanese,question-answering,10,128,2,7,2,1, -multicast-weights,4,fp16,best-throughput,2288.5,123.76
cl-tohoku/bert-base-japanese,fill-mask,6,128,6,2,1,2, -multicast-weights,2,fp16,best-throughput,674.2,37.62
cl-tohoku/bert-base-japanese-char,question-answering,10,128,2,7,,1, -multicast-weights,4,fp16,best-throughput,2496.8,113.1
cl-tohoku/bert-base-japanese-char,fill-mask,5,128,1,14,2,, ,3,fp16,best-throughput,2221.8,97.2
cl-tohoku/bert-base-japanese-whole-word-masking,question-answering,5,128,1,14,2,1, -multicast-weights,4,fp16,best-throughput,2421,117.57
cl-tohoku/bert-base-japanese-whole-word-masking,fill-mask,2,128,6,2,1,6, ,3,fp16,best-throughput,689.4,17.52
cross-encoder/ms-marco-MiniLM-L-12-v2,text-classification,5,128,1,14,4,1, ,4,fp16,best-throughput,5370.4,53.22
dbmdz/bert-base-italian-xxl-cased,question-answering,8,128,2,7,1,1, -multicast-weights,2,fp16,best-throughput,2430,46.81
dbmdz/bert-base-italian-xxl-cased,fill-mask,10,128,6,2,4,1, -multicast-weights,2,fp16,best-throughput,672.4,62.76
dbmdz/electra-base-german-europeana-cased-discriminator,question-answering,5,128,1,14,1,1, -multicast-weights,3,fp16,best-throughput,2472.3,86.16
dbmdz/electra-base-german-europeana-cased-discriminator,default,10,128,2,7,2,1, ,3,fp16,best-throughput,2325.1,91.61
DeepPavlov/rubert-base-cased-conversational,question-answering,5,128,1,14,4,2, -multicast-weights,1,fp16,best-throughput,2264.1,31.53
DeepPavlov/rubert-base-cased-conversational,feature-extraction,4,128,1,14,4,, ,4,fp16,best-throughput,2184.8,105.12
DeepPavlov/rubert-base-cased-sentence,question-answering,5,128,1,14,,1, ,4,fp16,best-throughput,2455.2,115.83
DeepPavlov/rubert-base-cased-sentence,feature-extraction,5,128,1,14,2,1, ,4,fp16,best-throughput,2070,157.71
deepset/roberta-base-squad2,question-answering,5,128,1,14,1,2, ,1,fp16,best-throughput,2307.8,30.7
deepset/xlm-roberta-large-squad2,question-answering,8,128,4,3,1,1, ,2,fp16,best-throughput,669.9,73.04
distilbert-base-cased,question-answering,5,128,1,14,1,1, ,4,fp16,best-throughput,4878.2,50.02
distilbert-base-cased,default,5,128,1,14,1,1, ,4,fp16,best-throughput,4904.1,57.74
distilbert-base-cased-distilled-squad,question-answering,5,128,1,14,2,1, ,3,fp16,best-throughput,4924.2,43.46
distilbert-base-german-cased,question-answering,10,128,2,7,1,1, -multicast-weights,3,fp16,best-throughput,4638.4,45.8
distilbert-base-german-cased,fill-mask,2,128,7,2,1,1, -multicast-weights,3,fp16,best-throughput,708.5,17.97
distilbert-base-multilingual-cased,question-answering,5,128,1,14,,, -multicast-weights,4,fp16,best-throughput,4394.7,64.77
distilbert-base-multilingual-cased,fill-mask,1,128,4,3,4,1, -multicast-weights,2,fp16,best-throughput,179,38.39
distilbert-base-uncased,question-answering,5,128,1,14,,2, ,3,fp16,best-throughput,4917.7,43.16
distilbert-base-uncased-distilled-squad,question-answering,5,128,1,14,4,1, ,4,fp16,best-throughput,4741,61.6
distilbert-base-uncased-finetuned-sst-2-english,text-classification,8,128,2,7,2,1, ,4,fp16,best-throughput,4965.8,46.06
distilbert-base-uncased-finetuned-sst-2-english,question-answering,10,128,2,7,1,1, -multicast-weights,3,fp16,best-throughput,4755.2,44.46
distilroberta-base,question-answering,5,128,1,14,,2, -multicast-weights,4,fp16,best-throughput,4532.7,62.7
distilroberta-base,fill-mask,1,128,12,1,1,12, -multicast-weights,3,fp16,best-throughput,453.5,6.89
dslim/bert-base-NER,token-classification,10,128,2,7,,1, -multicast-weights,3,fp16,best-throughput,2379.6,89.17
dslim/bert-base-NER-uncased,token-classification,10,128,2,7,2,1, -multicast-weights,3,fp16,best-throughput,2525.3,83.58
emilyalsentzer/Bio_ClinicalBERT,question-answering,5,128,1,14,1,1, -multicast-weights,2,fp16,best-throughput,2416.4,58.84
emilyalsentzer/Bio_ClinicalBERT,fill-mask,11,128,6,2,1,1, -multicast-weights,2,fp16,best-throughput,748,62.97
finiteautomata/beto-sentiment-analysis,text-classification,5,128,1,14,1,, -multicast-weights,4,fp16,best-throughput,2490,115.15
google/bert_uncased_L-2_H-128_A-2,question-answering,10,128,1,14,2,1, ,3,fp16,best-throughput,146152.9,3.02
google/bert_uncased_L-2_H-128_A-2,default,14,128,1,14,2,2, ,3,fp16,best-throughput,150041.4,4.23
google/electra-base-discriminator,question-answering,8,128,2,7,1,1, -multicast-weights,4,fp16,best-throughput,2344.2,96.73
google/electra-small-discriminator,question-answering,10,128,1,14,2,1, -multicast-weights,2,fp16,best-throughput,12075.2,24.52
google/electra-small-discriminator,default,8,128,1,14,4,, ,4,fp16,best-throughput,12318.4,37.15
hfl/chinese-bert-wwm-ext,question-answering,10,128,2,7,4,1, -multicast-weights,4,fp16,best-throughput,2203.2,128.83
hfl/chinese-bert-wwm-ext,fill-mask,6,128,4,3,,4, -multicast-weights,2,fp16,best-throughput,1014.3,37.63
hfl/chinese-electra-180g-base-discriminator,question-answering,5,128,1,14,1,, ,4,fp16,best-throughput,2446.4,115.99
hfl/chinese-electra-180g-base-discriminator,default,8,128,2,7,4,1, -multicast-weights,4,fp16,best-throughput,2531.1,89.78
hfl/chinese-roberta-wwm-ext,question-answering,10,128,2,7,1,1, -multicast-weights,2,fp16,best-throughput,2087.8,75.54
hfl/chinese-roberta-wwm-ext,fill-mask,4,128,3,4,2,3, ,3,fp16,best-throughput,992.4,57.43
kit-nlp/bert-base-japanese-sentiment-cyberbullying,question-answering,5,128,1,14,1,1, -multicast-weights,2,fp16,best-throughput,2295.6,61.66
kit-nlp/bert-base-japanese-sentiment-cyberbullying,default,5,128,1,14,4,1, -multicast-weights,2,fp16,best-throughput,2247.6,63.11
klue/bert-base,question-answering,5,128,1,14,,2, ,1,fp16,best-throughput,2326.6,30.51
klue/bert-base,fill-mask,7,128,7,2,,2, -multicast-weights,2,fp16,best-throughput,678.4,45.22
m3hrdadfi/bert-fa-base-uncased-wikinli,text-classification,10,128,2,7,1,1, -multicast-weights,3,fp16,best-throughput,2349.5,90.58
m3hrdadfi/bert-fa-base-uncased-wikinli,question-answering,5,128,1,14,,1, -multicast-weights,2,fp16,best-throughput,2301.7,61.51
Maltehb/danish-bert-botxo,question-answering,10,128,2,7,1,1, ,3,fp16,best-throughput,2488.5,85.24
Maltehb/danish-bert-botxo,fill-mask,8,128,7,2,,1, -multicast-weights,2,fp16,best-throughput,673.8,49.3
microsoft/codebert-base,question-answering,4,128,1,14,4,1, ,3,fp16,best-throughput,2352.2,73.04
microsoft/codebert-base,feature-extraction,8,128,2,7,1,1, -multicast-weights,3,fp16,best-throughput,2340.4,73.25
microsoft/deberta-v3-base,question-answering,14,128,7,2,4,1, ,3,fp16,best-throughput,1466,59.79
microsoft/deberta-v3-base,fill-mask,1,128,3,4,4,, -multicast-weights,2,fp16,best-throughput,162,57.74
microsoft/deberta-v3-small,question-answering,4,128,2,7,4,1, ,4,fp16,best-throughput,2740.1,41.87
microsoft/deberta-v3-small,fill-mask,1,128,7,2,1,7, ,4,fp16,best-throughput,160.7,58.11
monologg/bert-base-cased-goemotions-original,default,10,128,2,7,,1, -multicast-weights,3,fp16,best-throughput,2171.8,98.37
mrm8488/bert-spanish-cased-finetuned-ner,token-classification,8,128,2,7,2,1, ,2,fp16,best-throughput,2343.7,48.46
nlptown/bert-base-multilingual-uncased-sentiment,text-classification,8,128,2,7,2,1, -multicast-weights,3,fp16,best-throughput,2321.2,74.16
prajjwal1/bert-mini,question-answering,10,128,1,14,2,1, ,4,fp16,best-throughput,36120.9,16.23
prajjwal1/bert-mini,default,16,128,1,14,4,2, -multicast-weights,2,fp16,best-throughput,35880.6,13.11
prajjwal1/bert-tiny,question-answering,16,128,1,14,2,1, -multicast-weights,2,fp16,best-throughput,147519.4,3.18
prajjwal1/bert-tiny,default,16,128,1,14,2,1, -multicast-weights,3,fp16,best-throughput,142361.6,5.07
ProsusAI/finbert,text-classification,8,128,2,7,,1, ,4,fp16,best-throughput,2377.6,95.13
roberta-base,question-answering,5,128,1,14,4,1, ,2,fp16,best-throughput,2355.8,60.52
roberta-base,fill-mask,7,128,7,2,4,1, ,2,fp16,best-throughput,426.2,74.17
roberta-large,question-answering,14,128,7,2,4,1, -multicast-weights,1,fp16,best-throughput,696.2,41.09
roberta-large,fill-mask,4,128,2,7,4,1, ,4,fp16,best-throughput,382.8,306.37
roberta-large-mnli,default,6,128,2,7,2,1, -multicast-weights,3,fp16,best-throughput,688.5,184.69
Rostlab/prot_bert,question-answering,14,128,7,2,,1, ,1,fp16,best-throughput,558.8,51.1
sentence-transformers/all-distilroberta-v1,question-answering,4,128,1,14,4,1, -multicast-weights,2,fp16,best-throughput,4706.8,24.33
sentence-transformers/all-distilroberta-v1,default,10,128,2,7,,1, -multicast-weights,3,fp16,best-throughput,4627.1,46.08
sentence-transformers/all-MiniLM-L6-v2,question-answering,5,128,1,14,1,1, -multicast-weights,2,fp16,best-throughput,10290.6,13.78
sentence-transformers/all-MiniLM-L6-v2,default,4,128,1,14,2,, ,4,fp16,best-throughput,10388.6,22.08
sentence-transformers/all-mpnet-base-v2,question-answering,8,128,2,7,1,1, ,4,fp16,best-throughput,2399,94.45
sentence-transformers/all-mpnet-base-v2,default,6,128,2,7,1,1, ,4,fp16,best-throughput,2215.7,76.69
sentence-transformers/bert-base-nli-mean-tokens,question-answering,8,128,2,7,2,, -multicast-weights,2,fp16,best-throughput,2201.3,51.17
sentence-transformers/bert-base-nli-mean-tokens,default,5,128,1,14,,2, -multicast-weights,3,fp16,best-throughput,2277.1,93.96
sentence-transformers/distilbert-base-nli-stsb-mean-tokens,question-answering,5,128,1,14,,2, -multicast-weights,2,fp16,best-throughput,4727.4,29.85
sentence-transformers/distilbert-base-nli-stsb-mean-tokens,default,8,128,2,7,2,1, ,2,fp16,best-throughput,4945,22.84
sentence-transformers/msmarco-distilbert-base-tas-b,question-answering,8,128,2,7,4,1, ,2,fp16,best-throughput,4894.4,23.17
sentence-transformers/msmarco-distilbert-base-tas-b,default,10,128,2,7,1,1, ,3,fp16,best-throughput,4539.3,46.79
sentence-transformers/paraphrase-MiniLM-L6-v2,question-answering,4,128,1,14,2,, -multicast-weights,4,fp16,best-throughput,10210.1,22.86
sentence-transformers/paraphrase-MiniLM-L6-v2,default,4,128,1,14,2,, -multicast-weights,3,fp16,best-throughput,10353.4,16.64
sentence-transformers/paraphrase-mpnet-base-v2,question-answering,5,128,1,14,1,, -multicast-weights,3,fp16,best-throughput,2286.7,92.83
sentence-transformers/paraphrase-mpnet-base-v2,default,8,128,2,7,2,1, -multicast-weights,3,fp16,best-throughput,2255.6,75.67
sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2,question-answering,5,128,1,14,2,1, ,2,fp16,best-throughput,5330.6,26.95
sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2,default,4,128,1,14,2,1, -multicast-weights,3,fp16,best-throughput,5255.2,32.3
sentence-transformers/paraphrase-xlm-r-multilingual-v1,question-answering,8,128,2,7,4,1, -multicast-weights,3,fp16,best-throughput,2403.9,70.96
sentence-transformers/paraphrase-xlm-r-multilingual-v1,default,5,128,1,14,,1, -multicast-weights,1,fp16,best-throughput,2395,29.72
tals/albert-xlarge-vitaminc-mnli,default,4,128,4,3,2,, -multicast-weights,2,fp16,best-throughput,107.2,240.06
vinai/bertweet-base,question-answering,6,128,2,7,4,1, -multicast-weights,3,fp16,best-throughput,2249.1,56.79
vinai/bertweet-base,default,5,128,1,14,2,1, -multicast-weights,3,fp16,best-throughput,2373.8,89.7
vinai/phobert-base,question-answering,8,128,2,7,4,1, ,2,fp16,best-throughput,2331.7,49.13
vinai/phobert-base,default,10,128,2,7,2,1, ,2,fp16,best-throughput,2325.8,61.06
xlm-roberta-base,question-answering,5,128,1,14,,2, ,3,fp16,best-throughput,2402.6,88.27
xlm-roberta-base,default,8,128,2,7,1,1, -multicast-weights,4,fp16,best-throughput,2473.2,91.12
xlm-roberta-large,question-answering,14,128,7,2,1,1, -multicast-weights,2,fp16,best-throughput,725.3,77.83
xlm-roberta-large,default,6,128,2,7,2,1, -multicast-weights,3,fp16,best-throughput,678.9,188.32
xlm-roberta-large-finetuned-conll03-english,token-classification,9,128,3,4,2,1, -multicast-weights,2,fp16,best-throughput,662.6,109.28
yiyanghkust/finbert-tone,text-classification,4,128,1,14,4,1, -multicast-weights,4,fp16,best-throughput,2391.6,96.4
,,,,,,,,,,,,,
albert-base-v2,question-answering,6,128,2,7,4,1, ,1,fp16,balanced,2108.1,20.25
albert-base-v2,default,6,128,2,7,2,1, -multicast-weights,1,fp16,balanced,2108.3,20.4
allenai/scibert_scivocab_uncased,question-answering,4,128,2,7,4,1, -multicast-weights,1,fp16,balanced,2026.5,14.17
allenai/scibert_scivocab_uncased,default,8,128,2,7,2,1, ,1,fp16,balanced,2215.6,25.88
avichr/heBERT_sentiment_analysis,text-classification,5,128,1,14,1,, ,1,fp16,balanced,2228,31.98
beomi/kcbert-base,question-answering,14,128,2,7,2,1, ,1,fp16,balanced,1926.7,52.36
beomi/kcbert-base,fill-mask,3,128,4,3,2,1, ,2,fp16,balanced,720.1,25.19
bert-base-cased,question-answering,8,128,2,7,4,1, -multicast-weights,1,fp16,balanced,2370,24.03
bert-base-cased,fill-mask,5,128,7,2,2,1, ,2,fp16,balanced,748,27.5
bert-base-chinese,question-answering,8,128,2,7,2,1, ,1,fp16,balanced,2410.5,23.61
bert-base-chinese,fill-mask,12,128,4,3,2,, ,2,fp16,balanced,981.6,73.18
bert-base-german-cased,question-answering,12,128,3,4,,1, ,1,fp16,balanced,2070.4,23.88
bert-base-german-cased,fill-mask,9,128,6,2,1,1, -multicast-weights,2,fp16,balanced,710.7,53.89
bert-base-multilingual-cased,question-answering,6,128,2,7,2,, -multicast-weights,1,fp16,balanced,2061.2,20.91
bert-base-multilingual-cased,fill-mask,11,128,4,3,2,4, -multicast-weights,1,fp16,balanced,99.1,395.06
bert-base-multilingual-uncased,question-answering,14,128,14,1,2,1, -multicast-weights,1,fp16,balanced,1677.5,8.45
bert-base-multilingual-uncased,fill-mask,13,128,6,2,1,6, ,1,fp16,balanced,100.3,267.77
bert-base-uncased,question-answering,8,128,2,7,1,1, -multicast-weights,1,fp16,balanced,2363.4,23.95
bert-base-uncased,fill-mask,9,128,6,2,1,2, -multicast-weights,2,fp16,balanced,702.9,51.99
bert-large-uncased,question-answering,8,128,4,3,1,1, -multicast-weights,1,fp16,balanced,647.5,37.87
bert-large-uncased,fill-mask,4,128,2,7,4,1, -multicast-weights,2,fp16,balanced,519.8,112.25
bert-large-uncased-whole-word-masking-finetuned-squad,question-answering,4,128,2,7,,2, -multicast-weights,1,fp16,balanced,554.1,52.4
bert-large-uncased-whole-word-masking-finetuned-squad,default,4,128,1,14,4,, ,1,fp16,balanced,599.3,98.51
bhadresh-savani/distilbert-base-uncased-emotion,text-classification,5,128,1,14,2,1, ,1,fp16,balanced,4711.9,15.21
camembert-base,question-answering,5,128,1,14,4,, -multicast-weights,1,fp16,balanced,2204.8,32.1
camembert-base,fill-mask,9,128,1,14,1,1, ,1,fp16,balanced,427,372.15
cardiffnlp/twitter-roberta-base-sentiment,text-classification,10,128,2,7,2,1, ,1,fp16,balanced,2399.2,29.61
cardiffnlp/twitter-roberta-base-sentiment-latest,text-classification,10,128,2,7,4,, ,1,fp16,balanced,1927,36.88
ckiplab/albert-tiny-chinese,question-answering,15,128,3,4,1,, ,1,fp16,balanced,13384.3,4.46
ckiplab/albert-tiny-chinese,fill-mask,1,128,3,4,1,1, ,1,fp16,balanced,851.3,5.76
classla/bcms-bertic-ner,token-classification,10,128,2,7,4,1, -multicast-weights,1,fp16,balanced,2076.4,37.24
cl-tohoku/bert-base-japanese,question-answering,10,128,2,7,,1, -multicast-weights,1,fp16,balanced,2206.1,32.4
cl-tohoku/bert-base-japanese,fill-mask,9,128,6,2,1,6, -multicast-weights,2,fp16,balanced,668.9,53.42
cl-tohoku/bert-base-japanese-char,question-answering,10,128,2,7,,1, -multicast-weights,1,fp16,balanced,2445.2,28.98
cl-tohoku/bert-base-japanese-char,fill-mask,5,128,2,7,1,2, ,1,fp16,balanced,1416.5,26.59
cl-tohoku/bert-base-japanese-whole-word-masking,question-answering,16,128,2,7,4,1, ,1,fp16,balanced,2075.8,55.32
cl-tohoku/bert-base-japanese-whole-word-masking,fill-mask,9,128,7,2,4,1, -multicast-weights,2,fp16,balanced,665,53.72
cross-encoder/ms-marco-MiniLM-L-12-v2,text-classification,5,128,1,14,4,, ,1,fp16,balanced,5239.8,13.71
dbmdz/bert-base-italian-xxl-cased,question-answering,8,128,2,7,2,1, ,1,fp16,balanced,2139.4,26.8
dbmdz/bert-base-italian-xxl-cased,fill-mask,8,128,1,14,,1, -multicast-weights,1,fp16,balanced,515,323.35
dbmdz/electra-base-german-europeana-cased-discriminator,question-answering,4,128,1,14,2,2, -multicast-weights,1,fp16,balanced,2356.3,24.49
dbmdz/electra-base-german-europeana-cased-discriminator,default,10,128,2,7,4,1, -multicast-weights,1,fp16,balanced,2168.7,32.82
DeepPavlov/rubert-base-cased-conversational,question-answering,5,128,1,14,4,2, -multicast-weights,1,fp16,balanced,2264.1,31.53
DeepPavlov/rubert-base-cased-conversational,feature-extraction,6,128,1,14,4,, ,1,fp16,balanced,1975.8,44.36
DeepPavlov/rubert-base-cased-sentence,question-answering,5,128,1,14,,2, -multicast-weights,1,fp16,balanced,2211.8,32.25
DeepPavlov/rubert-base-cased-sentence,feature-extraction,4,128,1,14,,, ,1,fp16,balanced,2021.2,31.89
deepset/roberta-base-squad2,question-answering,5,128,1,14,1,2, ,1,fp16,balanced,2307.8,30.7
deepset/xlm-roberta-large-squad2,question-answering,8,128,2,7,,, ,1,fp16,balanced,557,102.28
distilbert-base-cased,question-answering,3,128,1,14,4,1, -multicast-weights,1,fp16,balanced,3782,11.87
distilbert-base-cased,default,5,128,1,14,1,1, ,1,fp16,balanced,3883.9,18.58
distilbert-base-cased-distilled-squad,question-answering,10,128,2,7,,1, ,1,fp16,balanced,4282.6,16.69
distilbert-base-german-cased,question-answering,8,128,6,2,2,, ,1,fp16,balanced,2437.7,6.64
distilbert-base-german-cased,fill-mask,1,128,1,14,4,1, -multicast-weights,1,fp16,balanced,552.5,37.96
distilbert-base-multilingual-cased,question-answering,3,128,2,7,4,1, ,1,fp16,balanced,2901.8,7.55
distilbert-base-multilingual-cased,fill-mask,10,128,7,2,4,1, ,1,fp16,balanced,89.7,237.26
distilbert-base-uncased,question-answering,5,128,1,14,,, -multicast-weights,1,fp16,balanced,4694.7,15.13
distilbert-base-uncased-distilled-squad,question-answering,6,128,2,7,4,1, ,1,fp16,balanced,4214.1,10.11
distilbert-base-uncased-finetuned-sst-2-english,text-classification,8,128,2,7,2,, -multicast-weights,1,fp16,balanced,3822.6,16.17
distilbert-base-uncased-finetuned-sst-2-english,question-answering,10,128,2,7,2,1, ,1,fp16,balanced,4507.2,15.79
distilroberta-base,question-answering,5,128,2,7,2,1, ,1,fp16,balanced,3659.4,9.75
distilroberta-base,fill-mask,10,128,1,14,2,1, -multicast-weights,1,fp16,balanced,279.9,629.14
dslim/bert-base-NER,token-classification,7,128,2,7,1,1, ,1,fp16,balanced,2018,24.7
dslim/bert-base-NER-uncased,token-classification,5,128,1,14,4,1, -multicast-weights,1,fp16,balanced,2073.4,34.61
emilyalsentzer/Bio_ClinicalBERT,question-answering,6,128,1,14,1,1, ,1,fp16,balanced,1949.3,45.92
emilyalsentzer/Bio_ClinicalBERT,fill-mask,11,128,7,2,1,1, -multicast-weights,2,fp16,balanced,742.6,61.88
finiteautomata/beto-sentiment-analysis,text-classification,5,128,1,14,2,1, ,1,fp16,balanced,2399.4,30.63
google/bert_uncased_L-2_H-128_A-2,question-answering,14,128,1,14,2,1, -multicast-weights,1,fp16,balanced,132797.1,1.62
google/bert_uncased_L-2_H-128_A-2,default,12,128,1,14,2,, ,1,fp16,balanced,98511.3,1.85
google/electra-base-discriminator,question-answering,5,128,1,14,1,2, ,1,fp16,balanced,2099.8,38.82
google/electra-small-discriminator,question-answering,12,128,1,14,4,, -multicast-weights,1,fp16,balanced,11764.1,14.89
google/electra-small-discriminator,default,9,128,1,14,4,2, -multicast-weights,1,fp16,balanced,11318.7,11.37
hfl/chinese-bert-wwm-ext,question-answering,4,128,1,14,4,1, ,1,fp16,balanced,2028.8,31.62
hfl/chinese-bert-wwm-ext,fill-mask,7,128,3,4,1,3, -multicast-weights,2,fp16,balanced,972.8,57.74
hfl/chinese-electra-180g-base-discriminator,question-answering,5,128,2,7,,2, -multicast-weights,1,fp16,balanced,1789.9,20.18
hfl/chinese-electra-180g-base-discriminator,default,8,128,1,14,4,1, ,1,fp16,balanced,1897.7,61.23
hfl/chinese-roberta-wwm-ext,question-answering,10,128,2,7,2,1, -multicast-weights,1,fp16,balanced,2083.7,37.39
hfl/chinese-roberta-wwm-ext,fill-mask,5,128,1,14,1,1, ,1,fp16,balanced,737.4,154.2
kit-nlp/bert-base-japanese-sentiment-cyberbullying,question-answering,5,128,1,14,1,1, -multicast-weights,1,fp16,balanced,2241.7,31.81
kit-nlp/bert-base-japanese-sentiment-cyberbullying,default,7,128,1,14,1,, ,1,fp16,balanced,1848.8,54.73
klue/bert-base,question-answering,5,128,1,14,,2, ,1,fp16,balanced,2326.6,30.51
klue/bert-base,fill-mask,3,128,1,14,1,, -multicast-weights,1,fp16,balanced,534.5,108.79
m3hrdadfi/bert-fa-base-uncased-wikinli,text-classification,8,128,2,7,,1, -multicast-weights,1,fp16,balanced,2302.5,24.71
m3hrdadfi/bert-fa-base-uncased-wikinli,question-answering,8,128,2,7,1,, -multicast-weights,1,fp16,balanced,2015.8,28.36
Maltehb/danish-bert-botxo,question-answering,4,128,2,7,1,1, ,1,fp16,balanced,2194.6,13.01
Maltehb/danish-bert-botxo,fill-mask,8,128,7,2,2,1, -multicast-weights,2,fp16,balanced,666.4,48.57
microsoft/codebert-base,question-answering,3,128,2,7,1,, ,1,fp16,balanced,1631.6,13.3
microsoft/codebert-base,feature-extraction,3,128,1,14,,2, ,1,fp16,balanced,1973.4,22.48
microsoft/deberta-v3-base,question-answering,8,128,4,3,4,1, -multicast-weights,1,fp16,balanced,1253.1,20.15
microsoft/deberta-v3-base,fill-mask,6,128,6,2,2,1, -multicast-weights,1,fp16,balanced,81.6,151.67
microsoft/deberta-v3-small,question-answering,6,128,3,4,,2, ,1,fp16,balanced,1815.7,13.61
microsoft/deberta-v3-small,fill-mask,5,128,7,2,2,1, ,2,fp16,balanced,158.2,123.73
monologg/bert-base-cased-goemotions-original,default,5,128,2,7,,, -multicast-weights,1,fp16,balanced,1682.3,21.26
mrm8488/bert-spanish-cased-finetuned-ner,token-classification,5,128,1,14,1,1, -multicast-weights,1,fp16,balanced,2280.8,31.04
nlptown/bert-base-multilingual-uncased-sentiment,text-classification,10,128,2,7,,1, -multicast-weights,1,fp16,balanced,2304.6,31.06
prajjwal1/bert-mini,question-answering,8,128,1,14,1,, -multicast-weights,1,fp16,balanced,33702.5,3.39
prajjwal1/bert-mini,default,12,128,1,14,4,2, -multicast-weights,1,fp16,balanced,30756.1,5.74
prajjwal1/bert-tiny,question-answering,16,128,1,14,2,, -multicast-weights,1,fp16,balanced,134589.4,1.76
prajjwal1/bert-tiny,default,13,128,1,14,2,1, ,1,fp16,balanced,108375.3,1.91
ProsusAI/finbert,text-classification,5,128,2,7,2,1, ,1,fp16,balanced,1967,18.06
roberta-base,question-answering,5,128,1,14,4,1, ,1,fp16,balanced,2319.5,30.83
roberta-base,fill-mask,6,128,7,2,4,1, ,2,fp16,balanced,426.1,57.96
roberta-large,question-answering,14,128,7,2,4,1, -multicast-weights,1,fp16,balanced,696.2,41.09
roberta-large,fill-mask,9,128,2,7,1,2, -multicast-weights,1,fp16,balanced,192.5,392.13
roberta-large-mnli,default,6,128,3,4,2,1, -multicast-weights,1,fp16,balanced,625,39.25
Rostlab/prot_bert,question-answering,14,128,7,2,,1, ,1,fp16,balanced,558.8,51.1
sentence-transformers/all-distilroberta-v1,question-answering,4,128,1,14,,, ,1,fp16,balanced,4512.8,13.07
sentence-transformers/all-distilroberta-v1,default,8,128,2,7,4,1, -multicast-weights,1,fp16,balanced,4195,13.81
sentence-transformers/all-MiniLM-L6-v2,question-answering,10,128,2,7,1,1, -multicast-weights,1,fp16,balanced,9744.8,7.27
sentence-transformers/all-MiniLM-L6-v2,default,5,128,1,14,,, ,1,fp16,balanced,9238.7,7.77
sentence-transformers/all-mpnet-base-v2,question-answering,11,128,3,4,2,1, ,1,fp16,balanced,1728.4,26.6
sentence-transformers/all-mpnet-base-v2,default,5,128,1,14,1,1, ,1,fp16,balanced,2040.1,35.25
sentence-transformers/bert-base-nli-mean-tokens,question-answering,6,128,2,7,2,, ,1,fp16,balanced,2075.5,20.51
sentence-transformers/bert-base-nli-mean-tokens,default,4,128,1,14,,, -multicast-weights,1,fp16,balanced,2172.9,26.63
sentence-transformers/distilbert-base-nli-stsb-mean-tokens,question-answering,4,128,1,14,4,2, -multicast-weights,1,fp16,balanced,4531.5,12.54
sentence-transformers/distilbert-base-nli-stsb-mean-tokens,default,6,128,2,7,1,1, ,1,fp16,balanced,4072.5,10.72
sentence-transformers/msmarco-distilbert-base-tas-b,question-answering,8,128,2,7,1,, ,1,fp16,balanced,3962.3,14.68
sentence-transformers/msmarco-distilbert-base-tas-b,default,4,128,1,14,2,1, ,1,fp16,balanced,4018.5,15.92
sentence-transformers/paraphrase-MiniLM-L6-v2,question-answering,4,128,1,14,4,1, ,1,fp16,balanced,9944.5,5.76
sentence-transformers/paraphrase-MiniLM-L6-v2,default,5,128,1,14,1,1, -multicast-weights,1,fp16,balanced,9292.7,7.7
sentence-transformers/paraphrase-mpnet-base-v2,question-answering,5,128,1,14,1,, -multicast-weights,1,fp16,balanced,2252.5,31.46
sentence-transformers/paraphrase-mpnet-base-v2,default,4,128,2,7,2,1, ,1,fp16,balanced,1943.2,14.72
sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2,question-answering,5,128,1,14,2,1, ,1,fp16,balanced,5175.1,13.87
sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2,default,7,128,2,7,2,, -multicast-weights,1,fp16,balanced,3838.2,13.01
sentence-transformers/paraphrase-xlm-r-multilingual-v1,question-answering,16,128,4,3,2,1, -multicast-weights,1,fp16,balanced,2062.7,24.46
sentence-transformers/paraphrase-xlm-r-multilingual-v1,default,5,128,1,14,,1, -multicast-weights,1,fp16,balanced,2395,29.72
tals/albert-xlarge-vitaminc-mnli,default,6,128,12,1,2,, -multicast-weights,1,fp16,balanced,101.1,59.64
vinai/bertweet-base,question-answering,6,128,1,14,4,2, ,1,fp16,balanced,1925.9,47.19
vinai/bertweet-base,default,5,128,1,14,2,1, -multicast-weights,1,fp16,balanced,2333.6,30.59
vinai/phobert-base,question-answering,5,128,1,14,,1, ,1,fp16,balanced,2239.3,31.79
vinai/phobert-base,default,8,128,2,7,2,1, ,1,fp16,balanced,2227.9,25.7
xlm-roberta-base,question-answering,7,128,1,14,,, -multicast-weights,1,fp16,balanced,1792.1,58.11
xlm-roberta-base,default,5,128,1,14,1,1, -multicast-weights,1,fp16,balanced,2398.3,29.77
xlm-roberta-large,question-answering,11,128,3,4,2,1, ,1,fp16,balanced,505.5,90.51
xlm-roberta-large,default,4,128,1,14,2,2, -multicast-weights,1,fp16,balanced,643,92.58
xlm-roberta-large-finetuned-conll03-english,token-classification,6,128,2,7,2,1, -multicast-weights,1,fp16,balanced,662.4,64.28
yiyanghkust/finbert-tone,text-classification,6,128,2,7,2,1, -multicast-weights,1,fp16,balanced,2189.8,19.55
,,,,,,,,,,,,,
albert-base-v2,question-answering,1,128,12,1,2,12, ,1,fp16,best-latency,531.9,1.99
albert-base-v2,default,1,128,12,1,2,12, -multicast-weights,1,fp16,best-latency,496.7,2.06
allenai/scibert_scivocab_uncased,question-answering,1,128,12,1,,12, ,1,fp16,best-latency,478.6,2.08
allenai/scibert_scivocab_uncased,default,1,128,12,1,1,12, ,1,fp16,best-latency,498.8,1.99
avichr/heBERT_sentiment_analysis,text-classification,1,128,14,1,1,1, ,1,fp16,best-latency,494.8,2.08
beomi/kcbert-base,question-answering,1,128,14,1,2,1, -multicast-weights,1,fp16,best-latency,479.4,2.17
beomi/kcbert-base,fill-mask,1,128,12,1,1,12, -multicast-weights,1,fp16,best-latency,159.1,6.67
bert-base-cased,question-answering,1,128,12,1,1,12, -multicast-weights,1,fp16,best-latency,497.9,2.09
bert-base-cased,fill-mask,1,128,14,1,1,1, ,1,fp16,best-latency,190.7,6.61
bert-base-chinese,question-answering,1,128,13,1,,1, -multicast-weights,1,fp16,best-latency,460.6,2.22
bert-base-chinese,fill-mask,1,128,12,1,1,12, -multicast-weights,1,fp16,best-latency,279.4,4.72
bert-base-german-cased,question-answering,1,128,12,1,,12, -multicast-weights,1,fp16,best-latency,497.9,2.08
bert-base-german-cased,fill-mask,1,128,14,1,1,1, -multicast-weights,1,fp16,best-latency,163,6.7
bert-base-multilingual-cased,question-answering,1,128,14,1,1,1, ,1,fp16,best-latency,456.4,2.31
bert-base-multilingual-cased,fill-mask,1,128,14,1,1,1, -multicast-weights,1,fp16,best-latency,45.5,23.1
bert-base-multilingual-uncased,question-answering,1,128,12,1,,12, -multicast-weights,1,fp16,best-latency,483.8,2.07
bert-base-multilingual-uncased,fill-mask,1,128,12,1,1,12, ,1,fp16,best-latency,57.7,19.72
bert-base-uncased,question-answering,1,128,14,1,2,14, -multicast-weights,1,fp16,best-latency,466.6,2.22
bert-base-uncased,fill-mask,1,128,14,1,2,1, ,2,fp16,best-latency,369.6,5.43
bert-large-uncased,question-answering,1,128,14,1,1,14, -multicast-weights,1,fp16,best-latency,169.7,5.97
bert-large-uncased,fill-mask,1,128,14,1,1,14, ,1,fp16,best-latency,89.4,11.51
bert-large-uncased-whole-word-masking-finetuned-squad,question-answering,1,128,14,1,1,14, ,1,fp16,best-latency,175.7,5.9
bert-large-uncased-whole-word-masking-finetuned-squad,default,1,128,12,1,1,12, ,1,fp16,best-latency,159.2,6.42
bhadresh-savani/distilbert-base-uncased-emotion,text-classification,1,128,14,1,1,14, -multicast-weights,1,fp16,best-latency,829.4,1.18
camembert-base,question-answering,1,128,12,1,1,12, -multicast-weights,1,fp16,best-latency,507.3,2.1
camembert-base,fill-mask,1,128,14,1,1,14, ,1,fp16,best-latency,153.4,7.03
cardiffnlp/twitter-roberta-base-sentiment,text-classification,1,128,12,1,2,12, -multicast-weights,1,fp16,best-latency,493.7,2.1
cardiffnlp/twitter-roberta-base-sentiment-latest,text-classification,1,128,12,1,1,12, ,1,fp16,best-latency,499.2,2.02
ckiplab/albert-tiny-chinese,question-answering,1,128,11,1,,11, ,1,fp16,best-latency,1812.1,0.58
ckiplab/albert-tiny-chinese,fill-mask,1,128,12,1,1,1, ,1,fp16,best-latency,476.8,2.15
classla/bcms-bertic-ner,token-classification,1,128,14,1,2,14, ,1,fp16,best-latency,499,2.02
cl-tohoku/bert-base-japanese,question-answering,1,128,13,1,2,2, ,1,fp16,best-latency,468.1,2.2
cl-tohoku/bert-base-japanese,fill-mask,1,128,14,1,1,1, -multicast-weights,1,fp16,best-latency,154.2,7.06
cl-tohoku/bert-base-japanese-char,question-answering,1,128,13,1,,2, -multicast-weights,1,fp16,best-latency,464.5,2.19
cl-tohoku/bert-base-japanese-char,fill-mask,1,128,12,1,1,12, ,1,fp16,best-latency,444.1,2.56
cl-tohoku/bert-base-japanese-whole-word-masking,question-answering,1,128,12,1,1,12, ,1,fp16,best-latency,497.4,2.08
cl-tohoku/bert-base-japanese-whole-word-masking,fill-mask,1,128,12,1,1,12, ,1,fp16,best-latency,139.4,7.22
cross-encoder/ms-marco-MiniLM-L-12-v2,text-classification,1,128,7,2,1,1, -multicast-weights,1,fp16,best-latency,1884.7,1.18
dbmdz/bert-base-italian-xxl-cased,question-answering,1,128,10,1,,2, -multicast-weights,1,fp16,best-latency,452.3,2.22
dbmdz/bert-base-italian-xxl-cased,fill-mask,1,128,14,1,1,14, ,1,fp16,best-latency,136.9,7.37
dbmdz/electra-base-german-europeana-cased-discriminator,question-answering,1,128,12,1,1,12, ,1,fp16,best-latency,506.3,2.05
dbmdz/electra-base-german-europeana-cased-discriminator,default,1,128,12,1,1,12, -multicast-weights,1,fp16,best-latency,471.6,2.2
DeepPavlov/rubert-base-cased-conversational,question-answering,1,128,14,1,2,2, -multicast-weights,1,fp16,best-latency,458.4,2.17
DeepPavlov/rubert-base-cased-conversational,feature-extraction,1,128,14,1,1,1, -multicast-weights,1,fp16,best-latency,461.8,2.21
DeepPavlov/rubert-base-cased-sentence,question-answering,1,128,12,1,,12, -multicast-weights,1,fp16,best-latency,536.5,1.97
DeepPavlov/rubert-base-cased-sentence,feature-extraction,1,128,12,1,1,12, -multicast-weights,1,fp16,best-latency,498.5,2.02
deepset/roberta-base-squad2,question-answering,1,128,13,1,2,2, -multicast-weights,1,fp16,best-latency,481,2.17
deepset/xlm-roberta-large-squad2,question-answering,1,128,14,1,1,14, ,1,fp16,best-latency,168.4,6.06
distilbert-base-cased,question-answering,1,128,13,1,1,13, -multicast-weights,1,fp16,best-latency,823.5,1.28
distilbert-base-cased,default,1,128,12,1,1,12, ,1,fp16,best-latency,829.9,1.2
distilbert-base-cased-distilled-squad,question-answering,1,128,11,1,1,1, -multicast-weights,1,fp16,best-latency,944,1.15
distilbert-base-german-cased,question-answering,1,128,11,1,,11, ,1,fp16,best-latency,928.4,1.16
distilbert-base-german-cased,fill-mask,1,128,12,1,1,12, ,3,fp16,best-latency,677.1,4.58
distilbert-base-multilingual-cased,question-answering,1,128,11,1,1,11, ,1,fp16,best-latency,900.1,1.17
distilbert-base-multilingual-cased,fill-mask,1,128,14,1,,2, ,3,fp16,best-latency,168.1,18.48
distilbert-base-uncased,question-answering,1,128,11,1,,1, ,1,fp16,best-latency,920.3,1.18
distilbert-base-uncased-distilled-squad,question-answering,1,128,11,1,,11, ,1,fp16,best-latency,907.4,1.16
distilbert-base-uncased-finetuned-sst-2-english,text-classification,1,128,12,1,1,, -multicast-weights,1,fp16,best-latency,736.6,1.38
distilbert-base-uncased-finetuned-sst-2-english,question-answering,1,128,10,1,1,1, ,1,fp16,best-latency,832.1,1.21
distilroberta-base,question-answering,1,128,14,1,,2, -multicast-weights,1,fp16,best-latency,990.9,1
distilroberta-base,fill-mask,1,128,12,1,1,12, -multicast-weights,3,fp16,best-latency,453.5,6.89
dslim/bert-base-NER,token-classification,1,128,12,1,1,12, ,1,fp16,best-latency,515.9,1.99
dslim/bert-base-NER-uncased,token-classification,1,128,12,1,1,12, ,1,fp16,best-latency,530.9,1.94
emilyalsentzer/Bio_ClinicalBERT,question-answering,1,128,12,1,1,12, -multicast-weights,1,fp16,best-latency,531.7,1.96
emilyalsentzer/Bio_ClinicalBERT,fill-mask,1,128,14,1,1,1, ,1,fp16,best-latency,201.2,6.4
finiteautomata/beto-sentiment-analysis,text-classification,1,128,12,1,2,12, ,1,fp16,best-latency,496.9,2.05
google/bert_uncased_L-2_H-128_A-2,question-answering,1,128,4,3,,2, -multicast-weights,1,fp16,best-latency,14107.6,0.31
google/bert_uncased_L-2_H-128_A-2,default,1,128,2,7,2,1, ,1,fp16,best-latency,33919.1,0.2
google/electra-base-discriminator,question-answering,1,128,12,1,2,12, -multicast-weights,1,fp16,best-latency,498.8,2.02
google/electra-small-discriminator,question-answering,1,128,4,3,1,4, ,1,fp16,best-latency,3383,1
google/electra-small-discriminator,default,1,128,12,1,1,12, ,1,fp16,best-latency,961.9,1.16
hfl/chinese-bert-wwm-ext,question-answering,1,128,12,1,1,12, -multicast-weights,1,fp16,best-latency,499.2,2.08
hfl/chinese-bert-wwm-ext,fill-mask,1,128,12,1,1,12, -multicast-weights,1,fp16,best-latency,196.7,5.09
hfl/chinese-electra-180g-base-discriminator,question-answering,1,128,12,1,2,12, ,1,fp16,best-latency,475.2,2.15
hfl/chinese-electra-180g-base-discriminator,default,1,128,14,1,1,1, -multicast-weights,1,fp16,best-latency,441.6,2.35
hfl/chinese-roberta-wwm-ext,question-answering,1,128,14,1,,14, -multicast-weights,1,fp16,best-latency,465.6,2.2
hfl/chinese-roberta-wwm-ext,fill-mask,1,128,14,1,2,14, -multicast-weights,2,fp16,best-latency,422,4.81
kit-nlp/bert-base-japanese-sentiment-cyberbullying,question-answering,1,128,12,1,1,12, ,1,fp16,best-latency,535,1.97
kit-nlp/bert-base-japanese-sentiment-cyberbullying,default,1,128,12,1,1,12, ,1,fp16,best-latency,498.3,1.99
klue/bert-base,question-answering,1,128,11,1,1,1, -multicast-weights,1,fp16,best-latency,452.3,2.22
klue/bert-base,fill-mask,1,128,14,1,1,1, ,1,fp16,best-latency,142.5,7.12
m3hrdadfi/bert-fa-base-uncased-wikinli,text-classification,1,128,12,1,2,12, ,1,fp16,best-latency,496.5,2.05
m3hrdadfi/bert-fa-base-uncased-wikinli,question-answering,1,128,12,1,,12, ,1,fp16,best-latency,512.4,2.03
Maltehb/danish-bert-botxo,question-answering,1,128,12,1,2,12, ,1,fp16,best-latency,490.6,2.06
Maltehb/danish-bert-botxo,fill-mask,1,128,14,1,1,14, -multicast-weights,1,fp16,best-latency,138.9,7.3
microsoft/codebert-base,question-answering,1,128,14,1,,2, -multicast-weights,1,fp16,best-latency,463.4,2.29
microsoft/codebert-base,feature-extraction,1,128,12,1,2,12, ,1,fp16,best-latency,452.7,2.3
microsoft/deberta-v3-base,question-answering,1,128,11,1,1,2, ,1,fp16,best-latency,359.6,2.8
microsoft/deberta-v3-base,fill-mask,1,128,12,1,1,12, -multicast-weights,1,fp16,best-latency,41.2,25.37
microsoft/deberta-v3-small,question-answering,1,128,11,1,,11, ,1,fp16,best-latency,704.9,1.52
microsoft/deberta-v3-small,fill-mask,1,128,12,1,1,12, -multicast-weights,2,fp16,best-latency,134.6,15.01
monologg/bert-base-cased-goemotions-original,default,1,128,12,1,1,12, -multicast-weights,1,fp16,best-latency,498.5,1.99
mrm8488/bert-spanish-cased-finetuned-ner,token-classification,1,128,14,1,2,14, ,1,fp16,best-latency,495.8,2.05
nlptown/bert-base-multilingual-uncased-sentiment,text-classification,1,128,12,1,2,12, -multicast-weights,1,fp16,best-latency,498.4,2.01
prajjwal1/bert-mini,question-answering,1,128,4,3,,2, ,1,fp16,best-latency,7484.2,0.43
prajjwal1/bert-mini,default,1,128,2,7,1,1, ,1,fp16,best-latency,17112.7,0.41
prajjwal1/bert-tiny,question-answering,1,128,4,3,1,1, -multicast-weights,1,fp16,best-latency,14294.9,0.22
prajjwal1/bert-tiny,default,1,128,1,14,1,1, ,1,fp16,best-latency,68062.1,0.21
ProsusAI/finbert,text-classification,1,128,12,1,1,12, ,1,fp16,best-latency,525.1,1.99
roberta-base,question-answering,1,128,12,1,2,12, -multicast-weights,1,fp16,best-latency,489.5,2.14
roberta-base,fill-mask,1,128,12,1,1,12, -multicast-weights,1,fp16,best-latency,110.4,10.39
roberta-large,question-answering,1,128,14,1,1,14, ,1,fp16,best-latency,169.6,6.03
roberta-large,fill-mask,1,128,14,1,,14, -multicast-weights,1,fp16,best-latency,74.6,14.73
roberta-large-mnli,default,1,128,14,1,1,14, -multicast-weights,1,fp16,best-latency,159.8,6.41
Rostlab/prot_bert,question-answering,1,128,14,1,1,1, -multicast-weights,1,fp16,best-latency,137,7.55
sentence-transformers/all-distilroberta-v1,question-answering,1,128,13,1,1,2, ,1,fp16,best-latency,956.4,1.12
sentence-transformers/all-distilroberta-v1,default,1,128,12,1,2,12, ,1,fp16,best-latency,961.2,1.12
sentence-transformers/all-MiniLM-L6-v2,question-answering,1,128,6,2,1,6, -multicast-weights,1,fp16,best-latency,3290,0.61
sentence-transformers/all-MiniLM-L6-v2,default,1,128,7,2,1,7, ,1,fp16,best-latency,3119.7,0.76
sentence-transformers/all-mpnet-base-v2,question-answering,1,128,11,1,1,11, -multicast-weights,1,fp16,best-latency,388.1,2.51
sentence-transformers/all-mpnet-base-v2,default,1,128,12,1,1,12, -multicast-weights,1,fp16,best-latency,428.7,2.34
sentence-transformers/bert-base-nli-mean-tokens,question-answering,1,128,12,1,,12, ,1,fp16,best-latency,493.3,2.09
sentence-transformers/bert-base-nli-mean-tokens,default,1,128,14,1,1,14, ,1,fp16,best-latency,453.4,2.21
sentence-transformers/distilbert-base-nli-stsb-mean-tokens,question-answering,1,128,10,1,1,10, ,1,fp16,best-latency,831.5,1.2
sentence-transformers/distilbert-base-nli-stsb-mean-tokens,default,1,128,12,1,1,12, -multicast-weights,1,fp16,best-latency,829.5,1.18
sentence-transformers/msmarco-distilbert-base-tas-b,question-answering,1,128,11,1,1,2, ,1,fp16,best-latency,834.4,1.2
sentence-transformers/msmarco-distilbert-base-tas-b,default,1,128,12,1,1,12, ,1,fp16,best-latency,823.1,1.29
sentence-transformers/paraphrase-MiniLM-L6-v2,question-answering,1,128,10,1,,10, ,1,fp16,best-latency,1621.8,0.7
sentence-transformers/paraphrase-MiniLM-L6-v2,default,1,128,6,2,1,1, ,1,fp16,best-latency,3306,0.61
sentence-transformers/paraphrase-mpnet-base-v2,question-answering,1,128,11,1,1,11, -multicast-weights,1,fp16,best-latency,423.4,2.38
sentence-transformers/paraphrase-mpnet-base-v2,default,1,128,12,1,2,12, -multicast-weights,1,fp16,best-latency,453.7,2.21
sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2,question-answering,1,128,10,1,1,2, ,1,fp16,best-latency,985.6,1.1
sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2,default,1,128,7,2,1,7, ,1,fp16,best-latency,1801.7,1.2
sentence-transformers/paraphrase-xlm-r-multilingual-v1,question-answering,1,128,12,1,1,12, -multicast-weights,1,fp16,best-latency,476.3,2.12
sentence-transformers/paraphrase-xlm-r-multilingual-v1,default,1,128,12,1,1,12, -multicast-weights,1,fp16,best-latency,447.6,2.31
tals/albert-xlarge-vitaminc-mnli,default,1,128,14,1,1,14, ,1,fp16,best-latency,44.2,22.71
vinai/bertweet-base,question-answering,1,128,14,1,2,2, -multicast-weights,1,fp16,best-latency,453.8,2.21
vinai/bertweet-base,default,1,128,12,1,1,12, -multicast-weights,1,fp16,best-latency,512.9,2.01
vinai/phobert-base,question-answering,1,128,14,1,,1, ,1,fp16,best-latency,461.8,2.2
vinai/phobert-base,default,1,128,14,1,1,14, ,1,fp16,best-latency,478,2.21
xlm-roberta-base,question-answering,1,128,12,1,,12, -multicast-weights,1,fp16,best-latency,506.7,2.05
xlm-roberta-base,default,1,128,12,1,1,12, -multicast-weights,1,fp16,best-latency,498.2,1.99
xlm-roberta-large,question-answering,1,128,14,1,,14, ,1,fp16,best-latency,173.5,5.98
xlm-roberta-large,default,1,128,14,1,2,1, ,1,fp16,best-latency,151.3,6.73
xlm-roberta-large-finetuned-conll03-english,token-classification,1,128,14,1,1,1, -multicast-weights,1,fp16,best-latency,169.8,6.02
yiyanghkust/finbert-tone,text-classification,1,128,12,1,1,12, ,1,fp16,best-latency,530.7,1.97
